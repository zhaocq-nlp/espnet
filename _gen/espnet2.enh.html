

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>espnet2.enh package &mdash; ESPnet 0.9.5 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="espnet2.utils package" href="espnet2.utils.html" />
    <link rel="prev" title="espnet2.schedulers package" href="espnet2.schedulers.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> ESPnet
          

          
          </a>

          
            
            
              <div class="version">
                0.9.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallelization.html">Using Job scheduling system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker.html">Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">ESPnet2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html">ESPnet2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html#instruction-for-run-sh">Instruction for run.sh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_training_option.html">Change the configuration for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_task.html">Task class and data input system for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_distributed.html">Distributed training</a></li>
</ul>
<p class="caption"><span class="caption-text">Notebook:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_cli.html">Speech Recognition (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_library.html">Speech Recognition (Library)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_cli.html">Text-to-Speech (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/pretrained.html">Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_realtime_demo.html">ESPnet real time E2E-TTS demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/st_demo.html">ESPnet Speech Translation Demonstration</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="espnet.st.html">espnet.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.lm.html">espnet.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.bin.html">espnet.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.scheduler.html">espnet.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.vc.html">espnet.vc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.utils.html">espnet.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.optimizer.html">espnet.optimizer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.nets.html">espnet.nets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.mt.html">espnet.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tasks.html">espnet2.tasks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.text.html">espnet2.text package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.optimizers.html">espnet2.optimizers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.torch_utils.html">espnet2.torch_utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.iterators.html">espnet2.iterators package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.lm.html">espnet2.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tts.html">espnet2.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.bin.html">espnet2.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.layers.html">espnet2.layers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.schedulers.html">espnet2.schedulers package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">espnet2.enh package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-enh-espnet-model">espnet2.enh.espnet_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-enh-abs-enh">espnet2.enh.abs_enh</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-enh-init">espnet2.enh.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-enh-layers-conv-beamformer">espnet2.enh.layers.conv_beamformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-enh-layers-dnn-beamformer">espnet2.enh.layers.dnn_beamformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-enh-layers-mask-estimator">espnet2.enh.layers.mask_estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-enh-layers-dnn-wpe">espnet2.enh.layers.dnn_wpe</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-enh-layers-init">espnet2.enh.layers.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-enh-nets-tf-mask-net">espnet2.enh.nets.tf_mask_net</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-enh-nets-beamformer-net">espnet2.enh.nets.beamformer_net</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-enh-nets-tasnet">espnet2.enh.nets.tasnet</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-enh-nets-init">espnet2.enh.nets.__init__</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.utils.html">espnet2.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.main_funcs.html">espnet2.main_funcs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asr.html">espnet2.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fileio.html">espnet2.fileio package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.samplers.html">espnet2.samplers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.train.html">espnet2.train package</a></li>
</ul>
<p class="caption"><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet2_bin.html">core tools (espnet2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_sh.html">bash utility tools</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ESPnet</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>espnet2.enh package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/_gen/espnet2.enh.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="espnet2-enh-package">
<h1>espnet2.enh package<a class="headerlink" href="#espnet2-enh-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="espnet2-enh-espnet-model">
<span id="id1"></span><h2>espnet2.enh.espnet_model<a class="headerlink" href="#espnet2-enh-espnet-model" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.enh.espnet_model"></span><dl class="class">
<dt id="espnet2.enh.espnet_model.ESPnetEnhancementModel">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.espnet_model.</code><code class="sig-name descname">ESPnetEnhancementModel</code><span class="sig-paren">(</span><em class="sig-param">enh_model: Optional[espnet2.enh.abs_enh.AbsEnhancement]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/espnet_model.html#ESPnetEnhancementModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.espnet_model.ESPnetEnhancementModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet2.train.html#espnet2.train.abs_espnet_model.AbsESPnetModel" title="espnet2.train.abs_espnet_model.AbsESPnetModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.train.abs_espnet_model.AbsESPnetModel</span></code></a></p>
<p>Speech enhancement or separation Frontend model</p>
<dl class="method">
<dt id="espnet2.enh.espnet_model.ESPnetEnhancementModel.collect_feats">
<code class="sig-name descname">collect_feats</code><span class="sig-paren">(</span><em class="sig-param">speech_mix: torch.Tensor</em>, <em class="sig-param">speech_mix_lengths: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/enh/espnet_model.html#ESPnetEnhancementModel.collect_feats"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.espnet_model.ESPnetEnhancementModel.collect_feats" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.enh.espnet_model.ESPnetEnhancementModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">speech_mix: torch.Tensor</em>, <em class="sig-param">speech_mix_lengths: torch.Tensor = None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Dict[str, torch.Tensor], torch.Tensor]<a class="reference internal" href="../_modules/espnet2/enh/espnet_model.html#ESPnetEnhancementModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.espnet_model.ESPnetEnhancementModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Frontend + Encoder + Decoder + Calc loss</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>speech_mix</strong> – (Batch, samples) or (Batch, samples, channels)</p></li>
<li><p><strong>speech_ref</strong> – (Batch, num_speaker, samples)
or (Batch, num_speaker, samples, channels)</p></li>
<li><p><strong>speech_mix_lengths</strong> – (Batch,), default None for chunk interator,
because the chunk-iterator does not have the
speech_lengths returned. see in
espnet2/iterators/chunk_iter_factory.py</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.enh.espnet_model.ESPnetEnhancementModel.si_snr_loss">
<em class="property">static </em><code class="sig-name descname">si_snr_loss</code><span class="sig-paren">(</span><em class="sig-param">ref</em>, <em class="sig-param">inf</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/espnet_model.html#ESPnetEnhancementModel.si_snr_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.espnet_model.ESPnetEnhancementModel.si_snr_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>si-snr loss</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ref</strong> – (Batch, samples)</p></li>
<li><p><strong>inf</strong> – (Batch, samples)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(Batch)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.enh.espnet_model.ESPnetEnhancementModel.si_snr_loss_zeromean">
<em class="property">static </em><code class="sig-name descname">si_snr_loss_zeromean</code><span class="sig-paren">(</span><em class="sig-param">ref</em>, <em class="sig-param">inf</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/espnet_model.html#ESPnetEnhancementModel.si_snr_loss_zeromean"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.espnet_model.ESPnetEnhancementModel.si_snr_loss_zeromean" title="Permalink to this definition">¶</a></dt>
<dd><p>si_snr loss with zero-mean in pre-processing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ref</strong> – (Batch, samples)</p></li>
<li><p><strong>inf</strong> – (Batch, samples)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(Batch)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.enh.espnet_model.ESPnetEnhancementModel.tf_l1_loss">
<em class="property">static </em><code class="sig-name descname">tf_l1_loss</code><span class="sig-paren">(</span><em class="sig-param">ref</em>, <em class="sig-param">inf</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/espnet_model.html#ESPnetEnhancementModel.tf_l1_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.espnet_model.ESPnetEnhancementModel.tf_l1_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>time-frequency L1 loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ref</strong> – (Batch, T, F) or (Batch, T, C, F)</p></li>
<li><p><strong>inf</strong> – (Batch, T, F) or (Batch, T, C, F)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(Batch)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.enh.espnet_model.ESPnetEnhancementModel.tf_mse_loss">
<em class="property">static </em><code class="sig-name descname">tf_mse_loss</code><span class="sig-paren">(</span><em class="sig-param">ref</em>, <em class="sig-param">inf</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/espnet_model.html#ESPnetEnhancementModel.tf_mse_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.espnet_model.ESPnetEnhancementModel.tf_mse_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>time-frequency MSE loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ref</strong> – (Batch, T, F)</p></li>
<li><p><strong>inf</strong> – (Batch, T, F)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(Batch)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet2-enh-abs-enh">
<span id="id2"></span><h2>espnet2.enh.abs_enh<a class="headerlink" href="#espnet2-enh-abs-enh" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.enh.abs_enh"></span><dl class="class">
<dt id="espnet2.enh.abs_enh.AbsEnhancement">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.abs_enh.</code><code class="sig-name descname">AbsEnhancement</code><a class="reference internal" href="../_modules/espnet2/enh/abs_enh.html#AbsEnhancement"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.abs_enh.AbsEnhancement" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.enh.abs_enh.AbsEnhancement.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, collections.OrderedDict]<a class="reference internal" href="../_modules/espnet2/enh/abs_enh.html#AbsEnhancement.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.abs_enh.AbsEnhancement.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="espnet2.enh.abs_enh.AbsEnhancement.forward_rawwav">
<em class="property">abstract </em><code class="sig-name descname">forward_rawwav</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, collections.OrderedDict]<a class="reference internal" href="../_modules/espnet2/enh/abs_enh.html#AbsEnhancement.forward_rawwav"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.abs_enh.AbsEnhancement.forward_rawwav" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet2-enh-init">
<span id="id3"></span><h2>espnet2.enh.__init__<a class="headerlink" href="#espnet2-enh-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.enh.__init__"></span></div>
<div class="section" id="espnet2-enh-layers-conv-beamformer">
<span id="id4"></span><h2>espnet2.enh.layers.conv_beamformer<a class="headerlink" href="#espnet2-enh-layers-conv-beamformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.enh.layers.conv_beamformer"></span><p>This script is used to construct convolutional beamformers.
Copyright 2020  Wangyou Zhang</p>
<blockquote>
<div><p>Apache 2.0  (<a class="reference external" href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a>)</p>
</div></blockquote>
<dl class="function">
<dt id="espnet2.enh.layers.conv_beamformer.get_WPD_filter">
<code class="sig-prename descclassname">espnet2.enh.layers.conv_beamformer.</code><code class="sig-name descname">get_WPD_filter</code><span class="sig-paren">(</span><em class="sig-param">Phi: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">Rf: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">reference_vector: torch.Tensor</em>, <em class="sig-param">eps: float = 1e-15</em><span class="sig-paren">)</span> &#x2192; torch_complex.tensor.ComplexTensor<a class="reference internal" href="../_modules/espnet2/enh/layers/conv_beamformer.html#get_WPD_filter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.conv_beamformer.get_WPD_filter" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the WPD vector.</p>
<blockquote>
<div><p>WPD is the Weighted Power minimization Distortionless response
convolutional beamformer. As follows:</p>
<p>h = (Rf^-1 &#64; Phi_{xx}) / tr[(Rf^-1) &#64; Phi_{xx}] &#64; u</p>
</div></blockquote>
<dl class="simple">
<dt>Reference:</dt><dd><p>T. Nakatani and K. Kinoshita, “A Unified Convolutional Beamformer
for Simultaneous Denoising and Dereverberation,” in IEEE Signal
Processing Letters, vol. 26, no. 6, pp. 903-907, June 2019, doi:
10.1109/LSP.2019.2911179.
<a class="reference external" href="https://ieeexplore.ieee.org/document/8691481">https://ieeexplore.ieee.org/document/8691481</a></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Phi</strong> (<em>ComplexTensor</em>) – (B, F, (btaps+1) * C, (btaps+1) * C)
is the PSD of zero-padded speech [x^T(t,f) 0 … 0]^T.</p></li>
<li><p><strong>Rf</strong> (<em>ComplexTensor</em>) – (B, F, (btaps+1) * C, (btaps+1) * C)
is the power normalized spatio-temporal covariance matrix.</p></li>
<li><p><strong>reference_vector</strong> (<em>torch.Tensor</em>) – (B, (btaps+1) * C)
is the reference_vector.</p></li>
<li><p><strong>eps</strong> (<em>float</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(B, F, (btaps + 1) * C)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>filter_matrix (ComplexTensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.enh.layers.conv_beamformer.get_WPD_filter_v2">
<code class="sig-prename descclassname">espnet2.enh.layers.conv_beamformer.</code><code class="sig-name descname">get_WPD_filter_v2</code><span class="sig-paren">(</span><em class="sig-param">Phi: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">Rf: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">reference_vector: torch.Tensor</em>, <em class="sig-param">eps: float = 1e-15</em><span class="sig-paren">)</span> &#x2192; torch_complex.tensor.ComplexTensor<a class="reference internal" href="../_modules/espnet2/enh/layers/conv_beamformer.html#get_WPD_filter_v2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.conv_beamformer.get_WPD_filter_v2" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the WPD vector with filter v2.</p>
<blockquote>
<div><blockquote>
<div><p>WPD is the Weighted Power minimization Distortionless response
convolutional beamformer. As follows:</p>
<p>h = (Rf^-1 &#64; Phi_{xx}) &#64; u / tr[(Rf^-1) &#64; Phi_{xx}]</p>
</div></blockquote>
<dl class="simple">
<dt>This implementaion is more efficient than <cite>get_WPD_filter</cite> as</dt><dd><p>it skips unnecessary computation with zeros.</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>Reference:</dt><dd><p>T. Nakatani and K. Kinoshita, “A Unified Convolutional Beamformer
for Simultaneous Denoising and Dereverberation,” in IEEE Signal
Processing Letters, vol. 26, no. 6, pp. 903-907, June 2019, doi:
10.1109/LSP.2019.2911179.
<a class="reference external" href="https://ieeexplore.ieee.org/document/8691481">https://ieeexplore.ieee.org/document/8691481</a></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Phi</strong> (<em>ComplexTensor</em>) – (B, F, C, C)
is speech PSD.</p></li>
<li><p><strong>Rf</strong> (<em>ComplexTensor</em>) – (B, F, (btaps+1) * C, (btaps+1) * C)
is the power normalized spatio-temporal covariance matrix.</p></li>
<li><p><strong>reference_vector</strong> (<em>torch.Tensor</em>) – (B, C)
is the reference_vector.</p></li>
<li><p><strong>eps</strong> (<em>float</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(B, F, (btaps+1) * C)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>filter_matrix (ComplexTensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.enh.layers.conv_beamformer.get_covariances">
<code class="sig-prename descclassname">espnet2.enh.layers.conv_beamformer.</code><code class="sig-name descname">get_covariances</code><span class="sig-paren">(</span><em class="sig-param">Y: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">inverse_power: torch.Tensor</em>, <em class="sig-param">bdelay: int</em>, <em class="sig-param">btaps: int</em>, <em class="sig-param">get_vector: bool = False</em><span class="sig-paren">)</span> &#x2192; torch_complex.tensor.ComplexTensor<a class="reference internal" href="../_modules/espnet2/enh/layers/conv_beamformer.html#get_covariances"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.conv_beamformer.get_covariances" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the power normalized spatio-temporal</p>
<blockquote>
<div><p>covariance matrix of the framed signal.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> – Complext STFT signal with shape (B, F, C, T)</p></li>
<li><p><strong>inverse_power</strong> – Weighting factor with shape (B, F, T)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Correlation matrix of shape (B, F, (btaps+1) * C, (btaps+1) * C)
Correlation vector of shape (B, F, btaps + 1, C, C)</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.enh.layers.conv_beamformer.inv">
<code class="sig-prename descclassname">espnet2.enh.layers.conv_beamformer.</code><code class="sig-name descname">inv</code><span class="sig-paren">(</span><em class="sig-param">z</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/layers/conv_beamformer.html#inv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.conv_beamformer.inv" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.enh.layers.conv_beamformer.perform_WPD_filtering">
<code class="sig-prename descclassname">espnet2.enh.layers.conv_beamformer.</code><code class="sig-name descname">perform_WPD_filtering</code><span class="sig-paren">(</span><em class="sig-param">filter_matrix: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">Y: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">bdelay: int</em>, <em class="sig-param">btaps: int</em><span class="sig-paren">)</span> &#x2192; torch_complex.tensor.ComplexTensor<a class="reference internal" href="../_modules/espnet2/enh/layers/conv_beamformer.html#perform_WPD_filtering"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.conv_beamformer.perform_WPD_filtering" title="Permalink to this definition">¶</a></dt>
<dd><p>perform_filter_operation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filter_matrix</strong> – Filter matrix (B, F, (btaps + 1) * C)</p></li>
<li><p><strong>Y</strong> – Complex STFT signal with shape (B, F, C, T)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(B, F, T)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>enhanced (ComplexTensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.enh.layers.conv_beamformer.signal_framing">
<code class="sig-prename descclassname">espnet2.enh.layers.conv_beamformer.</code><code class="sig-name descname">signal_framing</code><span class="sig-paren">(</span><em class="sig-param">signal: Union[torch.Tensor, torch_complex.tensor.ComplexTensor], frame_length: int, frame_step: int, bdelay: int, do_padding: bool = False, pad_value: int = 0, indices: List = None</em><span class="sig-paren">)</span> &#x2192; Union[torch.Tensor, torch_complex.tensor.ComplexTensor]<a class="reference internal" href="../_modules/espnet2/enh/layers/conv_beamformer.html#signal_framing"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.conv_beamformer.signal_framing" title="Permalink to this definition">¶</a></dt>
<dd><p>Expand <cite>signal</cite> into several frames, with each frame of length <cite>frame_length</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> – (…, T)</p></li>
<li><p><strong>frame_length</strong> – length of each segment</p></li>
<li><p><strong>frame_step</strong> – step for selecting frames</p></li>
<li><p><strong>bdelay</strong> – delay for WPD</p></li>
<li><p><strong>do_padding</strong> – whether or not to pad the input signal at the beginning
of the time dimension</p></li>
<li><p><strong>pad_value</strong> – value to fill in the padding</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>if do_padding: (…, T, frame_length)
else:          (…, T - bdelay - frame_length + 2, frame_length)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="espnet2-enh-layers-dnn-beamformer">
<span id="id5"></span><h2>espnet2.enh.layers.dnn_beamformer<a class="headerlink" href="#espnet2-enh-layers-dnn-beamformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.enh.layers.dnn_beamformer"></span><dl class="class">
<dt id="espnet2.enh.layers.dnn_beamformer.AttentionReference">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.layers.dnn_beamformer.</code><code class="sig-name descname">AttentionReference</code><span class="sig-paren">(</span><em class="sig-param">bidim</em>, <em class="sig-param">att_dim</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/layers/dnn_beamformer.html#AttentionReference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.dnn_beamformer.AttentionReference" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.enh.layers.dnn_beamformer.AttentionReference.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">psd_in: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">ilens: torch.LongTensor</em>, <em class="sig-param">scaling: float = 2.0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.LongTensor]<a class="reference internal" href="../_modules/espnet2/enh/layers/dnn_beamformer.html#AttentionReference.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.dnn_beamformer.AttentionReference.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The forward function</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>psd_in</strong> (<em>ComplexTensor</em>) – (B, F, C, C)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – (B,)</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(B, C)
ilens (torch.Tensor): (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>u (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.enh.layers.dnn_beamformer.DNN_Beamformer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.layers.dnn_beamformer.</code><code class="sig-name descname">DNN_Beamformer</code><span class="sig-paren">(</span><em class="sig-param">bidim</em>, <em class="sig-param">btype: str = 'blstmp'</em>, <em class="sig-param">blayers: int = 3</em>, <em class="sig-param">bunits: int = 300</em>, <em class="sig-param">bprojs: int = 320</em>, <em class="sig-param">num_spk: int = 1</em>, <em class="sig-param">use_noise_mask: bool = True</em>, <em class="sig-param">nonlinear: str = 'sigmoid'</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">badim: int = 320</em>, <em class="sig-param">ref_channel: int = -1</em>, <em class="sig-param">beamformer_type: str = 'mvdr'</em>, <em class="sig-param">eps: float = 1e-06</em>, <em class="sig-param">btaps: int = 5</em>, <em class="sig-param">bdelay: int = 3</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/layers/dnn_beamformer.html#DNN_Beamformer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.dnn_beamformer.DNN_Beamformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>DNN mask based Beamformer</p>
<dl class="simple">
<dt>Citation:</dt><dd><p>Multichannel End-to-end Speech Recognition; T. Ochiai et al., 2017;
<a class="reference external" href="https://arxiv.org/abs/1703.04783">https://arxiv.org/abs/1703.04783</a></p>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.enh.layers.dnn_beamformer.DNN_Beamformer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">data: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">ilens: torch.LongTensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch_complex.tensor.ComplexTensor, torch.LongTensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/enh/layers/dnn_beamformer.html#DNN_Beamformer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.dnn_beamformer.DNN_Beamformer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The forward function</p>
<dl class="simple">
<dt>Notation:</dt><dd><p>B: Batch
C: Channel
T: Time or Sequence length
F: Freq</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>ComplexTensor</em>) – (B, T, C, F), double precision</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(B, T, F), double precision
ilens (torch.Tensor): (B,)
masks (torch.Tensor): (B, T, C, F)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>enhanced (ComplexTensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.enh.layers.dnn_beamformer.DNN_Beamformer.predict_mask">
<code class="sig-name descname">predict_mask</code><span class="sig-paren">(</span><em class="sig-param">data: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">ilens: torch.LongTensor</em><span class="sig-paren">)</span> &#x2192; Tuple[Tuple[torch.Tensor, ...], torch.LongTensor]<a class="reference internal" href="../_modules/espnet2/enh/layers/dnn_beamformer.html#DNN_Beamformer.predict_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.dnn_beamformer.DNN_Beamformer.predict_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict masks for beamforming</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>ComplexTensor</em>) – (B, T, C, F), double precision</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(B, T, C, F)
ilens (torch.Tensor): (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>masks (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet2-enh-layers-mask-estimator">
<span id="id6"></span><h2>espnet2.enh.layers.mask_estimator<a class="headerlink" href="#espnet2-enh-layers-mask-estimator" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.enh.layers.mask_estimator"></span><dl class="class">
<dt id="espnet2.enh.layers.mask_estimator.MaskEstimator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.layers.mask_estimator.</code><code class="sig-name descname">MaskEstimator</code><span class="sig-paren">(</span><em class="sig-param">type</em>, <em class="sig-param">idim</em>, <em class="sig-param">layers</em>, <em class="sig-param">units</em>, <em class="sig-param">projs</em>, <em class="sig-param">dropout</em>, <em class="sig-param">nmask=1</em>, <em class="sig-param">nonlinear='sigmoid'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/layers/mask_estimator.html#MaskEstimator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.mask_estimator.MaskEstimator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.enh.layers.mask_estimator.MaskEstimator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">ilens: torch.LongTensor</em><span class="sig-paren">)</span> &#x2192; Tuple[Tuple[torch.Tensor, ...], torch.LongTensor]<a class="reference internal" href="../_modules/espnet2/enh/layers/mask_estimator.html#MaskEstimator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.mask_estimator.MaskEstimator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The forward function</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> – (B, F, C, T)</p></li>
<li><p><strong>ilens</strong> – (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The hidden vector (B, F, C, T)
masks: A tuple of the masks. (B, F, C, T)
ilens: (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>hs (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet2-enh-layers-dnn-wpe">
<span id="id7"></span><h2>espnet2.enh.layers.dnn_wpe<a class="headerlink" href="#espnet2-enh-layers-dnn-wpe" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.enh.layers.dnn_wpe"></span><dl class="class">
<dt id="espnet2.enh.layers.dnn_wpe.DNN_WPE">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.layers.dnn_wpe.</code><code class="sig-name descname">DNN_WPE</code><span class="sig-paren">(</span><em class="sig-param">wtype: str = 'blstmp'</em>, <em class="sig-param">widim: int = 257</em>, <em class="sig-param">wlayers: int = 3</em>, <em class="sig-param">wunits: int = 300</em>, <em class="sig-param">wprojs: int = 320</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">taps: int = 5</em>, <em class="sig-param">delay: int = 3</em>, <em class="sig-param">use_dnn_mask: bool = True</em>, <em class="sig-param">nonlinear: str = 'sigmoid'</em>, <em class="sig-param">iterations: int = 1</em>, <em class="sig-param">normalization: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/layers/dnn_wpe.html#DNN_WPE"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.dnn_wpe.DNN_WPE" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.enh.layers.dnn_wpe.DNN_WPE.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">data: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">ilens: torch.LongTensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch_complex.tensor.ComplexTensor, torch.LongTensor, torch_complex.tensor.ComplexTensor]<a class="reference internal" href="../_modules/espnet2/enh/layers/dnn_wpe.html#DNN_WPE.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.dnn_wpe.DNN_WPE.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The forward function</p>
<dl class="simple">
<dt>Notation:</dt><dd><p>B: Batch
C: Channel
T: Time or Sequence length
F: Freq or Some dimension of the feature vector</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – (B, C, T, F), double precision</p></li>
<li><p><strong>ilens</strong> – (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(B, C, T, F), double precision
ilens: (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>data</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.enh.layers.dnn_wpe.DNN_WPE.predict_mask">
<code class="sig-name descname">predict_mask</code><span class="sig-paren">(</span><em class="sig-param">data: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">ilens: torch.LongTensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.LongTensor]<a class="reference internal" href="../_modules/espnet2/enh/layers/dnn_wpe.html#DNN_WPE.predict_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.layers.dnn_wpe.DNN_WPE.predict_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict mask for WPE dereverberation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>ComplexTensor</em>) – (B, T, C, F), double precision</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(B, T, C, F)
ilens (torch.Tensor): (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>masks (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet2-enh-layers-init">
<span id="id8"></span><h2>espnet2.enh.layers.__init__<a class="headerlink" href="#espnet2-enh-layers-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.enh.layers.__init__"></span></div>
<div class="section" id="espnet2-enh-nets-tf-mask-net">
<span id="id9"></span><h2>espnet2.enh.nets.tf_mask_net<a class="headerlink" href="#espnet2-enh-nets-tf-mask-net" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.enh.nets.tf_mask_net"></span><dl class="class">
<dt id="espnet2.enh.nets.tf_mask_net.TFMaskingNet">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.nets.tf_mask_net.</code><code class="sig-name descname">TFMaskingNet</code><span class="sig-paren">(</span><em class="sig-param">n_fft: int = 512</em>, <em class="sig-param">win_length: int = None</em>, <em class="sig-param">hop_length: int = 128</em>, <em class="sig-param">rnn_type: str = 'blstm'</em>, <em class="sig-param">layer: int = 3</em>, <em class="sig-param">unit: int = 512</em>, <em class="sig-param">dropout: float = 0.0</em>, <em class="sig-param">num_spk: int = 2</em>, <em class="sig-param">nonlinear: str = 'sigmoid'</em>, <em class="sig-param">utt_mvn: bool = False</em>, <em class="sig-param">mask_type: str = 'IRM'</em>, <em class="sig-param">loss_type: str = 'mask_mse'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tf_mask_net.html#TFMaskingNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tf_mask_net.TFMaskingNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.enh.abs_enh.AbsEnhancement" title="espnet2.enh.abs_enh.AbsEnhancement"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.enh.abs_enh.AbsEnhancement</span></code></a></p>
<p>TF Masking Speech Separation Net.</p>
<dl class="method">
<dt id="espnet2.enh.nets.tf_mask_net.TFMaskingNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tf_mask_net.html#TFMaskingNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tf_mask_net.TFMaskingNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>torch.Tensor</em>) – mixed speech [Batch, sample]</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – input lengths [Batch]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>[(B, T, F), …]
ilens (torch.Tensor): (B,)
predcited masks: OrderedDict[</p>
<blockquote>
<div><p>’spk1’: torch.Tensor(Batch, Frames, Channel, Freq),
‘spk2’: torch.Tensor(Batch, Frames, Channel, Freq),
…
‘spkn’: torch.Tensor(Batch, Frames, Channel, Freq),</p>
</div></blockquote>
<p>]</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>separated (list[ComplexTensor])</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.enh.nets.tf_mask_net.TFMaskingNet.forward_rawwav">
<code class="sig-name descname">forward_rawwav</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/enh/nets/tf_mask_net.html#TFMaskingNet.forward_rawwav"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tf_mask_net.TFMaskingNet.forward_rawwav" title="Permalink to this definition">¶</a></dt>
<dd><p>Output with waveforms.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>torch.Tensor</em>) – mixed speech [Batch, sample]</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – input lengths [Batch]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>predcited speech [Batch, num_speaker, sample]
output lengths
predcited masks: OrderedDict[</p>
<blockquote>
<div><p>’spk1’: torch.Tensor(Batch, Frames, Channel, Freq),
‘spk2’: torch.Tensor(Batch, Frames, Channel, Freq),
…
‘spkn’: torch.Tensor(Batch, Frames, Channel, Freq),</p>
</div></blockquote>
<p>]</p>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet2-enh-nets-beamformer-net">
<span id="id10"></span><h2>espnet2.enh.nets.beamformer_net<a class="headerlink" href="#espnet2-enh-nets-beamformer-net" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.enh.nets.beamformer_net"></span><dl class="class">
<dt id="espnet2.enh.nets.beamformer_net.BeamformerNet">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.nets.beamformer_net.</code><code class="sig-name descname">BeamformerNet</code><span class="sig-paren">(</span><em class="sig-param">num_spk: int = 1</em>, <em class="sig-param">normalize_input: bool = False</em>, <em class="sig-param">mask_type: str = 'IPM^2'</em>, <em class="sig-param">loss_type: str = 'mask_mse'</em>, <em class="sig-param">n_fft: int = 512</em>, <em class="sig-param">win_length: int = None</em>, <em class="sig-param">hop_length: int = 128</em>, <em class="sig-param">center: bool = True</em>, <em class="sig-param">window: Optional[str] = 'hann'</em>, <em class="sig-param">normalized: bool = False</em>, <em class="sig-param">onesided: bool = True</em>, <em class="sig-param">use_wpe: bool = False</em>, <em class="sig-param">wnet_type: str = 'blstmp'</em>, <em class="sig-param">wlayers: int = 3</em>, <em class="sig-param">wunits: int = 300</em>, <em class="sig-param">wprojs: int = 320</em>, <em class="sig-param">wdropout_rate: float = 0.0</em>, <em class="sig-param">taps: int = 5</em>, <em class="sig-param">delay: int = 3</em>, <em class="sig-param">use_dnn_mask_for_wpe: bool = True</em>, <em class="sig-param">wnonlinear: str = 'crelu'</em>, <em class="sig-param">use_beamformer: bool = True</em>, <em class="sig-param">bnet_type: str = 'blstmp'</em>, <em class="sig-param">blayers: int = 3</em>, <em class="sig-param">bunits: int = 300</em>, <em class="sig-param">bprojs: int = 320</em>, <em class="sig-param">badim: int = 320</em>, <em class="sig-param">ref_channel: int = -1</em>, <em class="sig-param">use_noise_mask: bool = True</em>, <em class="sig-param">bnonlinear: str = 'sigmoid'</em>, <em class="sig-param">beamformer_type='mvdr'</em>, <em class="sig-param">bdropout_rate=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/beamformer_net.html#BeamformerNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.beamformer_net.BeamformerNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.enh.abs_enh.AbsEnhancement" title="espnet2.enh.abs_enh.AbsEnhancement"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.enh.abs_enh.AbsEnhancement</span></code></a></p>
<p>TF Masking based beamformer</p>
<dl class="method">
<dt id="espnet2.enh.nets.beamformer_net.BeamformerNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/beamformer_net.html#BeamformerNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.beamformer_net.BeamformerNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>torch.Tensor</em>) – mixed speech [Batch, Nsample, Channel]</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – input lengths [Batch]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>torch.Tensor or List[torch.Tensor]
output lengths
predcited masks: OrderedDict[</p>
<blockquote>
<div><p>’dereverb’: torch.Tensor(Batch, Frames, Channel, Freq),
‘spk1’: torch.Tensor(Batch, Frames, Channel, Freq),
‘spk2’: torch.Tensor(Batch, Frames, Channel, Freq),
…
‘spkn’: torch.Tensor(Batch, Frames, Channel, Freq),
‘noise1’: torch.Tensor(Batch, Frames, Channel, Freq),</p>
</div></blockquote>
<p>]</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>enhanced speech  (single-channel)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.enh.nets.beamformer_net.BeamformerNet.forward_rawwav">
<code class="sig-name descname">forward_rawwav</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/beamformer_net.html#BeamformerNet.forward_rawwav"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.beamformer_net.BeamformerNet.forward_rawwav" title="Permalink to this definition">¶</a></dt>
<dd><p>Output with wavformes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>torch.Tensor</em>) – mixed speech [Batch, Nsample, Channel]</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – input lengths [Batch]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>torch.Tensor(Batch, Nsamples), or List[torch.Tensor(Batch, Nsamples)]
output lengths
predcited masks: OrderedDict[</p>
<blockquote>
<div><p>’dereverb’: torch.Tensor(Batch, Frames, Channel, Freq),
‘spk1’: torch.Tensor(Batch, Frames, Channel, Freq),
‘spk2’: torch.Tensor(Batch, Frames, Channel, Freq),
…
‘spkn’: torch.Tensor(Batch, Frames, Channel, Freq),
‘noise1’: torch.Tensor(Batch, Frames, Channel, Freq),</p>
</div></blockquote>
<p>]</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>predcited speech wavs (single-channel)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet2-enh-nets-tasnet">
<span id="id11"></span><h2>espnet2.enh.nets.tasnet<a class="headerlink" href="#espnet2-enh-nets-tasnet" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.enh.nets.tasnet"></span><dl class="class">
<dt id="espnet2.enh.nets.tasnet.ChannelwiseLayerNorm">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">ChannelwiseLayerNorm</code><span class="sig-paren">(</span><em class="sig-param">channel_size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#ChannelwiseLayerNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.ChannelwiseLayerNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Channel-wise Layer Normalization (cLN)</p>
<dl class="method">
<dt id="espnet2.enh.nets.tasnet.ChannelwiseLayerNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#ChannelwiseLayerNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.ChannelwiseLayerNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> – [M, N, K], M is batch size, N is channel size, K is length</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[M, N, K]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>cLN_y</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.enh.nets.tasnet.ChannelwiseLayerNorm.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#ChannelwiseLayerNorm.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.ChannelwiseLayerNorm.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.enh.nets.tasnet.Chomp1d">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">Chomp1d</code><span class="sig-paren">(</span><em class="sig-param">chomp_size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#Chomp1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.Chomp1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>To ensure the output length is the same as the input.</p>
<dl class="method">
<dt id="espnet2.enh.nets.tasnet.Chomp1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#Chomp1d.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.Chomp1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – [M, H, Kpad]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[M, H, K]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.enh.nets.tasnet.Decoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">Decoder</code><span class="sig-paren">(</span><em class="sig-param">N</em>, <em class="sig-param">L</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#Decoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.Decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.enh.nets.tasnet.Decoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">mixture_w</em>, <em class="sig-param">est_mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#Decoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.Decoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mixture_w</strong> – [M, N, K]</p></li>
<li><p><strong>est_mask</strong> – [M, C, N, K]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[M, C, T]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>est_source</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.enh.nets.tasnet.DepthwiseSeparableConv">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">DepthwiseSeparableConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride</em>, <em class="sig-param">padding</em>, <em class="sig-param">dilation</em>, <em class="sig-param">norm_type='gLN'</em>, <em class="sig-param">causal=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#DepthwiseSeparableConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.DepthwiseSeparableConv" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.enh.nets.tasnet.DepthwiseSeparableConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#DepthwiseSeparableConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.DepthwiseSeparableConv.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – [M, H, K]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[M, B, K]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>result</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.enh.nets.tasnet.Encoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">Encoder</code><span class="sig-paren">(</span><em class="sig-param">L</em>, <em class="sig-param">N</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Estimation of the nonnegative mixture weight by a 1-D conv layer.</p>
<dl class="method">
<dt id="espnet2.enh.nets.tasnet.Encoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">mixture</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#Encoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mixture</strong> – [M, T], M is batch size, T is #samples</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[M, N, K], where K = (T-L)/(L/2)+1 = 2T/L-1</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>mixture_w</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.enh.nets.tasnet.GlobalLayerNorm">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">GlobalLayerNorm</code><span class="sig-paren">(</span><em class="sig-param">channel_size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#GlobalLayerNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.GlobalLayerNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Global Layer Normalization (gLN)</p>
<dl class="method">
<dt id="espnet2.enh.nets.tasnet.GlobalLayerNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#GlobalLayerNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.GlobalLayerNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> – [M, N, K], M is batch size, N is channel size, K is length</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[M, N, K]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>gLN_y</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.enh.nets.tasnet.GlobalLayerNorm.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#GlobalLayerNorm.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.GlobalLayerNorm.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.enh.nets.tasnet.TasNet">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">TasNet</code><span class="sig-paren">(</span><em class="sig-param">N: int = 256</em>, <em class="sig-param">L: int = 20</em>, <em class="sig-param">B: int = 256</em>, <em class="sig-param">H: int = 512</em>, <em class="sig-param">P: int = 3</em>, <em class="sig-param">X: int = 8</em>, <em class="sig-param">R: int = 4</em>, <em class="sig-param">num_spk: int = 2</em>, <em class="sig-param">norm_type: str = 'gLN'</em>, <em class="sig-param">causal: bool = False</em>, <em class="sig-param">mask_nonlinear: str = 'relu'</em>, <em class="sig-param">loss_type: str = 'si_snr'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#TasNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.TasNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.enh.abs_enh.AbsEnhancement" title="espnet2.enh.abs_enh.AbsEnhancement"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.enh.abs_enh.AbsEnhancement</span></code></a></p>
<p>Main tasnet class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> – Number of filters in autoencoder</p></li>
<li><p><strong>L</strong> – Length of the filters (in samples)</p></li>
<li><p><strong>B</strong> – Number of channels in bottleneck 1 * 1-conv block</p></li>
<li><p><strong>H</strong> – Number of channels in convolutional blocks</p></li>
<li><p><strong>P</strong> – Kernel size in convolutional blocks</p></li>
<li><p><strong>X</strong> – Number of convolutional blocks in each repeat</p></li>
<li><p><strong>R</strong> – Number of repeats</p></li>
<li><p><strong>num_spk</strong> – Number of speakers</p></li>
<li><p><strong>norm_type</strong> – BN, gLN, cLN</p></li>
<li><p><strong>causal</strong> – causal or non-causal</p></li>
<li><p><strong>mask_nonlinear</strong> – use which non-linear function to generate mask</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Reference:</dt><dd><p>Luo Y, Mesgarani N. Tasnet: time-domain audio
separation network for real-time, single-channel speech separation</p>
</dd>
</dl>
<p>Based on <a class="reference external" href="https://github.com/kaituoxu/Conv-TasNet">https://github.com/kaituoxu/Conv-TasNet</a></p>
<dl class="method">
<dt id="espnet2.enh.nets.tasnet.TasNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">mixture</em>, <em class="sig-param">ilens=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#TasNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.TasNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward from mixture to estimation sources.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mixture</strong> – [M, T], M is batch size, T is #samples</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – input lengths [Batch]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[M, C, T]
lens:  [Batch]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>est_source</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.enh.nets.tasnet.TasNet.forward_rawwav">
<code class="sig-name descname">forward_rawwav</code><span class="sig-paren">(</span><em class="sig-param">mixture</em>, <em class="sig-param">ilens=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#TasNet.forward_rawwav"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.TasNet.forward_rawwav" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.enh.nets.tasnet.TasNet.load_model">
<em class="property">classmethod </em><code class="sig-name descname">load_model</code><span class="sig-paren">(</span><em class="sig-param">path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#TasNet.load_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.TasNet.load_model" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.enh.nets.tasnet.TasNet.load_model_from_package">
<em class="property">classmethod </em><code class="sig-name descname">load_model_from_package</code><span class="sig-paren">(</span><em class="sig-param">package</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#TasNet.load_model_from_package"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.TasNet.load_model_from_package" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.enh.nets.tasnet.TasNet.serialize">
<em class="property">static </em><code class="sig-name descname">serialize</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">optimizer</em>, <em class="sig-param">epoch</em>, <em class="sig-param">tr_loss=None</em>, <em class="sig-param">cv_loss=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#TasNet.serialize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.TasNet.serialize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.enh.nets.tasnet.TemporalBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">TemporalBlock</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride</em>, <em class="sig-param">padding</em>, <em class="sig-param">dilation</em>, <em class="sig-param">norm_type='gLN'</em>, <em class="sig-param">causal=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#TemporalBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.TemporalBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.enh.nets.tasnet.TemporalBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#TemporalBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.TemporalBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – [M, B, K]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[M, B, K]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.enh.nets.tasnet.TemporalConvNet">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">TemporalConvNet</code><span class="sig-paren">(</span><em class="sig-param">N</em>, <em class="sig-param">B</em>, <em class="sig-param">H</em>, <em class="sig-param">P</em>, <em class="sig-param">X</em>, <em class="sig-param">R</em>, <em class="sig-param">C</em>, <em class="sig-param">norm_type='gLN'</em>, <em class="sig-param">causal=False</em>, <em class="sig-param">mask_nonlinear='relu'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#TemporalConvNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.TemporalConvNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Basic Module of tasnet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> – Number of filters in autoencoder</p></li>
<li><p><strong>B</strong> – Number of channels in bottleneck 1 * 1-conv block</p></li>
<li><p><strong>H</strong> – Number of channels in convolutional blocks</p></li>
<li><p><strong>P</strong> – Kernel size in convolutional blocks</p></li>
<li><p><strong>X</strong> – Number of convolutional blocks in each repeat</p></li>
<li><p><strong>R</strong> – Number of repeats</p></li>
<li><p><strong>C</strong> – Number of speakers</p></li>
<li><p><strong>norm_type</strong> – BN, gLN, cLN</p></li>
<li><p><strong>causal</strong> – causal or non-causal</p></li>
<li><p><strong>mask_nonlinear</strong> – use which non-linear function to generate mask</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.enh.nets.tasnet.TemporalConvNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">mixture_w</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#TemporalConvNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.TemporalConvNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Keep this API same with TasNet</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mixture_w</strong> – [M, N, K], M is batch size</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[M, C, N, K]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>est_mask</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.enh.nets.tasnet.check_nonlinear">
<code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">check_nonlinear</code><span class="sig-paren">(</span><em class="sig-param">nolinear_type</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#check_nonlinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.check_nonlinear" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.enh.nets.tasnet.chose_norm">
<code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">chose_norm</code><span class="sig-paren">(</span><em class="sig-param">norm_type</em>, <em class="sig-param">channel_size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#chose_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.chose_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>The input of normalization will be (M, C, K), where M is batch size.</p>
<p>C is channel size and K is sequence length.</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.enh.nets.tasnet.overlap_and_add">
<code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">overlap_and_add</code><span class="sig-paren">(</span><em class="sig-param">signal</em>, <em class="sig-param">frame_step</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#overlap_and_add"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.overlap_and_add" title="Permalink to this definition">¶</a></dt>
<dd><p>Reconstructs a signal from a framed representation.</p>
<p>Adds potentially overlapping frames of a signal with shape
<cite>[…, frames, frame_length]</cite>, offsetting subsequent frames by <cite>frame_step</cite>.
The resulting tensor has shape <cite>[…, output_size]</cite> where</p>
<blockquote>
<div><p>output_size = (frames - 1) * frame_step + frame_length</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signal</strong> – A […, frames, frame_length] Tensor.
All dimensions may be unknown, and rank must be at least 2.</p></li>
<li><p><strong>frame_step</strong> – An integer denoting overlap offsets.
Must be less than or equal to frame_length.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A Tensor with shape […, output_size] containing the</dt><dd><p>overlap-added frames of signal’s inner-most two dimensions.</p>
</dd>
</dl>
<p>output_size = (frames - 1) * frame_step + frame_length</p>
</p>
</dd>
</dl>
<dl class="simple">
<dt>Based on <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/r1.12/">https://github.com/tensorflow/tensorflow/blob/r1.12/</a></dt><dd><p>tensorflow/contrib/signal/python/ops/reconstruction_ops.py</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.enh.nets.tasnet.remove_pad">
<code class="sig-prename descclassname">espnet2.enh.nets.tasnet.</code><code class="sig-name descname">remove_pad</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">inputs_lengths</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/enh/nets/tasnet.html#remove_pad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.enh.nets.tasnet.remove_pad" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove pad.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – torch.Tensor, [B, C, T] or [B, T], B is batch size</p></li>
<li><p><strong>inputs_lengths</strong> – torch.Tensor, [B]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a list containing B items, each item is [C, T], T varies</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>results</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="espnet2-enh-nets-init">
<span id="id12"></span><h2>espnet2.enh.nets.__init__<a class="headerlink" href="#espnet2-enh-nets-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.enh.nets.__init__"></span></div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="espnet2.utils.html" class="btn btn-neutral float-right" title="espnet2.utils package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="espnet2.schedulers.html" class="btn btn-neutral float-left" title="espnet2.schedulers package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2017, Shinji Watanabe

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>